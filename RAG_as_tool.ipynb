{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87d532ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, BaseMessage,SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49db3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding=HuggingFaceEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5a287e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model_name=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40ba8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Effective Approaches to Attention-based Neural Machine Translation.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6eea3a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42f976aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b20d1e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ecee231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.08', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-09-21T20:33:39-04:00', 'moddate': '2015-09-21T20:33:39-04:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': 'Effective Approaches to Attention-based Neural Machine Translation.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1'}, page_content='arXiv:1508.04025v5  [cs.CL]  20 Sep 2015\\nEffective Approaches to Attention-based Neural Machine Translation\\nMinh-Thang Luong Hieu Pham Christopher D. Manning\\nComputer Science Department, Stanford University, Stanford, CA 94305\\n{lmthang,hyhieu,manning}@stanford.edu\\nAbstract\\nAn attentional mechanism has lately been\\nused to improve neural machine transla-\\ntion (NMT) by selectively focusing on\\nparts of the source sentence during trans-\\nlation. However, there has been little\\nwork exploring useful architectures for\\nattention-based NMT. This paper exam-\\nines two simple and effective classes of at-\\ntentional mechanism: a global approach\\nwhich always attends to all source words\\nand a local one that only looks at a subset\\nof source words at a time. We demonstrate\\nthe effectiveness of both approaches on the\\nWMT translation tasks between English\\nand German in both directions. With local\\nattention, we achieve a signiﬁcant gain of\\n5.0 BLEU points over non-attentional sys-')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72269279",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=FAISS.from_documents(chunks,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea0102b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x13d6a89d0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9914f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b67e6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=retriever.invoke(\"attention is a key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59e2e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_tool(query):\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the pdf document.\n",
    "    Use this tool when the user asks factual / conceptual questions\n",
    "    that might be answered from the stored documents.\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "\n",
    "    context = [doc.page_content for doc in result]\n",
    "    metadata = [doc.metadata for doc in result]\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'context': context,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f70cb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [rag_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a791713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6dee0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2af68239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31b86995",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node('chat_node', chat_node)\n",
    "graph.add_node('tools', tool_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_conditional_edges('chat_node', tools_condition)\n",
    "graph.add_edge('tools', 'chat_node')\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0651625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x13d6ab230>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa635b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chatbot.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            \n",
    "            \n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    \"what is attention \"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13e74595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Attention – A Quick Overview\n",
      "\n",
      "**Attention** is a mechanism in machine learning (especially in natural language processing, computer vision, and multimodal tasks) that allows a model to focus on the most relevant parts of its input when making a prediction. Think of it like a spotlight that highlights the most important words, image regions, or other features, letting the model weigh them more heavily than irrelevant or noisy parts.\n",
      "\n",
      "---\n",
      "\n",
      "#### 1. Why Attention Was Introduced\n",
      "- **Limitations of RNNs**: Recurrent networks (LSTMs, GRUs) struggle to remember long‑range dependencies because information gets diluted as it passes through many time‑steps.\n",
      "- **Fixed‑size context**: Traditional encoders produce a single fixed‑length vector that must capture all relevant information, which is hard for long sequences.\n",
      "- **Parallelization**: Attention can be computed in parallel across all positions, speeding up training and inference.\n",
      "\n",
      "---\n",
      "\n",
      "#### 2. Core Idea\n",
      "At its heart, attention computes a **weighted sum** over a set of input vectors, where the weights (attention scores) are learned dynamically based on the current query.\n",
      "\n",
      "- **Query**: The current element that needs context (e.g., the current word being decoded).\n",
      "- **Keys**: Representations of all input elements (e.g., encoder outputs for all words).\n",
      "- **Values**: Usually the same as keys, or additional representations that will be combined.\n",
      "\n",
      "The model learns to assign higher weights to keys that are more relevant to the query.\n",
      "\n",
      "---\n",
      "\n",
      "#### 3. Scaled Dot‑Product Attention (Transformer style)\n",
      "\n",
      "For a single attention head:\n",
      "\n",
      "1. **Compute scores**  \n",
      "   \\[\n",
      "   \\text{scores} = \\frac{QK^\\top}{\\sqrt{d_k}}\n",
      "   \\]\n",
      "   where \\(Q, K\\) are query and key matrices, and \\(d_k\\) is the dimensionality of the keys.\n",
      "\n",
      "2. **Softmax**  \n",
      "   \\[\n",
      "   \\alpha = \\text{softmax}(\\text{scores})\n",
      "   \\]\n",
      "   Produces a probability distribution over the keys.\n",
      "\n",
      "3. **Weighted sum**  \n",
      "   \\[\n",
      "   \\text{output} = \\alpha V\n",
      "   \\]\n",
      "   where \\(V\\) is the value matrix.\n",
      "\n",
      "This operation is differentiable, so the model learns the linear projections that produce \\(Q, K, V\\) through back‑propagation.\n",
      "\n",
      "---\n",
      "\n",
      "#### 4. Multi‑Head Attention\n",
      "Instead of a single attention head, the Transformer uses multiple heads in parallel. Each head learns a different representation of “what to attend to”:\n",
      "\n",
      "\\[\n",
      "\\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W^O\n",
      "\\]\n",
      "\n",
      "- **h**: number of heads (e.g., 8 or 12).\n",
      "- \\(W^O\\): output projection matrix.\n",
      "\n",
      "This increases the model’s capacity to capture diverse relationships.\n",
      "\n",
      "---\n",
      "\n",
      "#### 5. Types of Attention\n",
      "\n",
      "| Type | Use‑case | Example |\n",
      "|------|----------|---------|\n",
      "| **Self‑Attention** | Input attends to itself (e.g., Transformer encoder). | “The cat sat on the mat.” Each word looks at all other words. |\n",
      "| **Cross‑Attention** | Query comes from one sequence, keys/values from another (e.g., decoder attends to encoder outputs). | Machine translation: decoder word attends to encoder hidden states. |\n",
      "| **Bahdanau/Luong Attention** | Earlier seq‑2‑seq models used additive or dot‑product attention. | “I love you” → “Je t’aime”. |\n",
      "| **Sparse / Local Attention** | Limit attention to a local window for efficiency. | Long‑document summarization. |\n",
      "| **Multi‑Modal Attention** | Attend across modalities (text, image, audio). | Visual question answering. |\n",
      "\n",
      "---\n",
      "\n",
      "#### 6. Attention in Vision\n",
      "\n",
      "- **Vision Transformers (ViT)**: Treat image patches as tokens and use self‑attention to capture global relationships.\n",
      "- **Attention‑based Object Detection**: Models like DETR use cross‑attention between image features and object queries.\n",
      "\n",
      "---\n",
      "\n",
      "#### 7. Practical Impact\n",
      "\n",
      "| Problem | Attention Helps |\n",
      "|---------|-----------------|\n",
      "| Long‑range dependencies | By focusing on relevant tokens, it mitigates vanishing gradients. |\n",
      "| Interpretability | Attention weights can be visualized to see which words/regions influence predictions. |\n",
      "| Parallelism | Allows full‑sequence processing in GPUs, drastically speeding up training. |\n",
      "| Transfer learning | Transformers pre‑trained with attention (e.g., BERT, GPT, ViT) transfer well to many downstream tasks. |\n",
      "\n",
      "---\n",
      "\n",
      "#### 8. Quick Example (Python pseudo‑code)\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "\n",
      "def scaled_dot_product_attention(Q, K, V):\n",
      "    d_k = Q.size(-1)\n",
      "    scores = torch.matmul(Q, K.transpose(-2, -1)) / d_k**0.5\n",
      "    attn = F.softmax(scores, dim=-1)\n",
      "    return torch.matmul(attn, V), attn\n",
      "\n",
      "# Dummy tensors\n",
      "Q = torch.randn(1, 5, 64)   # query (batch, seq_len, dim)\n",
      "K = torch.randn(1, 10, 64)  # key\n",
      "V = torch.randn(1, 10, 64)  # value\n",
      "\n",
      "output, attn_weights = scaled_dot_product_attention(Q, K, V)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "#### 9. Common Misconceptions\n",
      "\n",
      "- **Attention ≠ explainability**: While attention maps are intuitive, they don’t always correlate with model explanations.\n",
      "- **Attention is always beneficial**: In some cases, simpler models (e.g., RNNs with gating) can outperform attention on small datasets.\n",
      "- **More heads = better**: Adding heads increases capacity but also computation and risk of over‑fitting.\n",
      "\n",
      "---\n",
      "\n",
      "#### 10. Resources to Dive Deeper\n",
      "\n",
      "- **Original Transformer Paper**: *Attention Is All You Need* (Vaswani et al., 2017)\n",
      "- **Attention Mechanisms**: *Neural Machine Translation by Jointly Learning to Align and Translate* (Bahdanau et al., 2015)\n",
      "- **Vision Transformer**: *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale* (Dosovitskiy et al., 2020)\n",
      "- **Tutorials**: Hugging Face Transformers docs, fast.ai, DeepMind’s *Attention and Transformers* lecture series.\n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR\n",
      "Attention is a dynamic weighting scheme that lets models focus on the most relevant parts of their input, enabling better handling of long sequences, improved interpretability, and efficient parallel computation—forming the backbone of modern NLP and computer vision architectures.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eee975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
